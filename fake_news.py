# -*- coding: utf-8 -*-
"""fake_news.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mmnOJvmKUjo9WyfH_-all6zocIN4y_KS
"""

import numpy as np
import pandas as pd

# 데이터 불러오기

test = pd.read_csv("/content/drive/MyDrive/fake-news/test.csv")
train = pd.read_csv("/content/drive/MyDrive/fake-news/train.csv")
submit = pd.read_csv("/content/drive/MyDrive/fake-news/submit.csv")

test.head()

train.head()

submit.head()

train.text[0:1]

for i in range(5):
  print(f'{i+1}번째 기사')
  print(train.text[i])

print(train.shape)
print(test.shape)

train[train['label']==1]

train[train['label']==0]

train.isnull().sum()

test.isnull().sum()

# 비어 있는 곳은 다 빈칸으로 남겨두기.

train = train.fillna('')
test = test.fillna('')

"""### Stemming:
- Stemming은 linguistic normalisation 하는 과정이다. 
- 어근만 남기게 되어, 같은 어근을 가지고 있다면 동일한 언어로 취급할 수 있게 한다.


"""

import re
import nltk
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer

# 불용어를 먼저 다운로드 받아 보자. 
nltk.download('stopwords')

print(stopwords.words('english'))
print(len(stopwords.words('english')), "개의 불용어가 있음.")

port_stem = PorterStemmer()

def stemming(content):
    review = re.sub('[^a-zA-Z]',' ',content)
    review = review.lower()
    review = review.split()
    review = [port_stem.stem(word) for word in review if not word in stopwords.words('english')]
    review = ' '.join(review)
    return review

train['content'] = train['author']+' '+train['title']

print(train['content'])

X = train.drop('label',axis=1)
X
Y = train['label']

Y

Y.value_counts()

train['content'] = train['content'].apply(stemming)
print(train['content'])

print(train['content'][0])

X = train['content'].values
Y = train['label'].values
X

"""### TF-IDF
- Term Frequency - Inverse Document Frequency
- 모든 문서에 자주 등장하는 단어는 중요도가 낮다.
- 특정 문서에서 자주 등장하는 단어는 중요도가 높다.

"""

#수치화가 필요함.

from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer= TfidfVectorizer()
vectorizer.fit(X)
X = vectorizer.transform(X)

print(X)
print(Y)

from sklearn.model_selection import train_test_split

X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2, stratify=Y, random_state=2)

# stratify 는 classification을 다룰 때 매우 중요함. stratify를 target으로 지정해주면
# 각각의 class 비율을 train/validation에 유지해줍니다.

from sklearn.linear_model import LogisticRegression

model = LogisticRegression()
model.fit(X_train,Y_train)

from sklearn.metrics import accuracy_score

X_train_prediction = model.predict(X_train)
training_data_accuracy = accuracy_score(X_train_prediction, Y_train)

print(training_data_accuracy)

X_test_prediction = model.predict(X_test)
test_data_accuracy = accuracy_score(X_test_prediction, Y_test)
print(test_data_accuracy)

# Confusion matrix 그려보기

import matplotlib.pyplot as plt

def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Purples):
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")
        
    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

X__train, X__test,Y__train,Y__test = train_test_split(X,Y,test_size=0.33, random_state=42)

"""### classification model : Multinomial naive bayes

- NLP에서 많이 사용하는 모델이다.
- TF를 사용한다.
- 자세한 내용은 따로 정리하자!


"""

from sklearn.naive_bayes import MultinomialNB
classifier=MultinomialNB()

from sklearn import metrics
import itertools

classifier.fit(X__train, Y__train)
prediction__ = classifier.predict(X__test)
score = metrics.accuracy_score(Y__test,prediction__)
print(f'accuracy : {round(score,3)}')
cm1 = metrics.confusion_matrix(Y__test, prediction__)
plot_confusion_matrix(cm1, classes=['Fake','Real'])

"""### classification model : passive aggressive classifier

- online learning 의 한 방법.
"""

X2_train, X2_test, Y2_train, Y2_test = train_test_split(X, Y, test_size=0.33, random_state=42)

from sklearn.linear_model import PassiveAggressiveClassifier
linear_clf = PassiveAggressiveClassifier(max_iter=50)

linear_clf.fit(X2_train, Y2_train)
prediction2 = linear_clf.predict(X2_test)
score = metrics.accuracy_score(Y2_test, prediction2)
print("accuracy:   %0.3f" % score)
cm2 = metrics.confusion_matrix(Y2_test, prediction2)
plot_confusion_matrix(cm2, classes=['FAKE Data', 'REAL Data'])

"""###  Buildling a predictive system


"""

# Logistic Regression

X_new = X_test[0]

prediction = model.predict(X_new)
print(prediction)

if(prediction[0] ==0):
  print('The news is Real')
else:
  print('The news is fuckin\' Fake')

# multinomial naive bayes
X1_new = X__test[0]

prediction = model.predict(X1_new)
print(prediction)

if (prediction[0]==0):
  print('The news is Real')
else:
  print('The news is fuckin\' Fake')

# passive aggressive classifier

X2_new = X2_test[0]

prediction = model.predict(X2_new)
print(prediction)

if (prediction[0]==0):
  print('The news is Real')
else:
  print('The news is Fake')

# report

# show the prediction, recall, F1 Score ,,,

from sklearn.metrics import classification_report
print("Logistic Regression report")
print(classification_report(Y_test,X_test_prediction))
print("="*60)
print("Multinomial NB report")
print(classification_report(Y__test,prediction__))
print("="*60)
print("Passive Aggressive report")
print(classification_report(Y2_test,prediction2))
print("="*60)

"""Passive Aggressive model 이 가장 정확도가 높게 나왔다."""

