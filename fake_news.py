# -*- coding: utf-8 -*-
"""fake_news.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mmnOJvmKUjo9WyfH_-all6zocIN4y_KS
"""

import numpy as np
import pandas as pd

# 데이터 불러오기

test = pd.read_csv("/content/drive/MyDrive/fake-news/test.csv")
train = pd.read_csv("/content/drive/MyDrive/fake-news/train.csv")
submit = pd.read_csv("/content/drive/MyDrive/fake-news/submit.csv")

test.head()

train.head()

submit.head()

train.text[0:1]

for i in range(5):
  print(f'{i+1}번째 기사')
  print(train.text[i])

print(train.shape)
print(test.shape)

train[train['label']==1]

train[train['label']==0]

train.isnull().sum()

test.isnull().sum()

# 비어 있는 곳은 다 빈칸으로 남겨두기.

train = train.fillna('')
test = test.fillna('')

"""### Stemming:
- Stemming은 linguistic normalisation 하는 과정이다. 
- 어근만 남기게 되어, 같은 어근을 가지고 있다면 동일한 언어로 취급할 수 있게 한다.


"""

import re
import nltk
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer

# 불용어를 먼저 다운로드 받아 보자. 
nltk.download('stopwords')

print(stopwords.words('english'))
print(len(stopwords.words('english')), "개의 불용어가 있음.")

port_stem = PorterStemmer()

def stemming(content):
    review = re.sub('[^a-zA-Z]',' ',content)
    review = review.lower()
    review = review.split()
    review = [port_stem.stem(word) for word in review if not word in stopwords.words('english')]
    review = ' '.join(review)
    return review



